{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5272e94c",
   "metadata": {},
   "source": [
    "# RAG Research Summarizer with Claude (Proof of Concept)\n",
    "This script uses Anthropic's Claude to answer queries using relevant research summaries.\n",
    "\n",
    "## Setup:\n",
    "1. Add your API key to a file called ignore.py at the same directory level as this script:\n",
    "\n",
    "    KEY = \"your_claude_api_key_here\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf881731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (2.8.0)\n",
      "Requirement already satisfied: sentence-transformers in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (5.1.2)\n",
      "Requirement already satisfied: anthropic in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (0.72.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: jinja2 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: networkx in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: filelock in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: fsspec in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: tqdm in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (4.57.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: Pillow in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from anthropic) (1.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from anthropic) (4.11.0)\n",
      "Requirement already satisfied: sniffio in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from anthropic) (1.3.1)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.15 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from anthropic) (0.17.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from anthropic) (0.11.1)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from anthropic) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from anthropic) (2.12.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->anthropic) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->anthropic) (3.11)\n",
      "Requirement already satisfied: certifi in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.25.0->anthropic) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
      "Requirement already satisfied: requests in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->anthropic) (2.41.5)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch sentence-transformers anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e298a7c2",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8000a0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import ignore\n",
    "\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import anthropic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22617b3b",
   "metadata": {},
   "source": [
    "# extract documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5551ddec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_001||A longitudinal study of 1,200 middle school students found that incorporating spaced repetition into mathematics curriculum improved long-term retention by 42% compared to massed practice. Students who reviewed concepts at intervals of 1, 3, and 7 days showed significantly better performance on assessments administered three months later.\n",
      "doc_002||Research examining 500 undergraduate students revealed that handwritten notes led to 23% better conceptual understanding compared to laptop note-taking. The constraint of slower handwriting appeared to force students to process and synthesize information more deeply during lectures.\n",
      "doc_003||A meta-analysis of 74 studies found that peer tutoring programs increased academic achievement by an average effect size of 0.59 standard deviations. Benefits were particularly pronounced when tutors were trained in questioning techniques and given structured materials.\n",
      "doc_004||Investigation of 15 elementary schools implementing project-based learning showed mixed results: while student engagement increased by 67%, standardized test scores showed no significant improvement in the first two years of implementation. Teachers reported needing 18-24 months to effectively adapt their practice.\n",
      "doc_005||Analysis of online learning outcomes during 2020-2021 revealed that synchronous video classes with breakout rooms achieved 89% of the learning gains of in-person instruction, while asynchronous-only formats achieved only 64%. Student isolation was the primary predictor of poor outcomes.\n"
     ]
    }
   ],
   "source": [
    "docs = json.load(open('./documents.json', 'r'))\n",
    "docs = [f'{k}||{v}' for k, v in docs.items()]  # Make them a list with some metadata fusion.\n",
    "\n",
    "for doc in docs[:5]:  # print a few docs as an example\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34302a0e",
   "metadata": {},
   "source": [
    "# cosine similarity function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92af8a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_top_k(model: SentenceTransformer, query: str, doc_embs: torch.Tensor, docs: list[str], k: int = 3) -> list[tuple[float, str]]:\n",
    "    \"\"\"\n",
    "    Perform a cosine similarity search for a query against precomputed document embeddings.\n",
    "\n",
    "    Args:\n",
    "        model (SentenceTransformer): Preloaded Huggingface embedding model.\n",
    "        query (str): Query string.\n",
    "        doc_embs (torch.Tensor): Precomputed document embeddings (normalized).\n",
    "        docs (List[str]): Original documents corresponding to embeddings.\n",
    "        k (int, optional): Number of top results to return. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        list[Tuple[float, str]]: List of (similarity_score, document) tuples.\n",
    "    \"\"\"\n",
    "    query_emb = model.encode([query], convert_to_tensor=True, normalize_embeddings=True)\n",
    "    sims = util.cos_sim(query_emb, doc_embs)[0]  # shape: [num_docs]\n",
    "    top_k = torch.topk(sims, k=k)\n",
    "    return [(score.item(), docs[idx]) for idx, score in zip(top_k.indices, top_k.values)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b34cce6",
   "metadata": {},
   "source": [
    "# build model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2855932",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "doc_embs = model.encode(docs, convert_to_tensor=True, normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d26b30a",
   "metadata": {},
   "source": [
    "### example search usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9dd3a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5860 | doc_012||Research on outdoor education programs found that students who spent at least 2 hours per week in nature-based learning showed 26% reduction in stress markers and 18% improvement in creative problem-solving tasks compared to indoor-only control groups.\n",
      "0.3282 | doc_004||Investigation of 15 elementary schools implementing project-based learning showed mixed results: while student engagement increased by 67%, standardized test scores showed no significant improvement in the first two years of implementation. Teachers reported needing 18-24 months to effectively adapt their practice.\n",
      "0.2837 | doc_005||Analysis of online learning outcomes during 2020-2021 revealed that synchronous video classes with breakout rooms achieved 89% of the learning gains of in-person instruction, while asynchronous-only formats achieved only 64%. Student isolation was the primary predictor of poor outcomes.\n"
     ]
    }
   ],
   "source": [
    "query = 'what do we know about outdoor education'\n",
    "n = 3\n",
    "\n",
    "results = search_top_k(model, query, doc_embs, docs, k=n)\n",
    "\n",
    "for score, doc in results:\n",
    "    print(f\"{score:.4f} | {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a167ffd",
   "metadata": {},
   "source": [
    "# prompt building and generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b27dd541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(query: str, sources: int = 3, print_flag: bool = False) -> str:\n",
    "    results = search_top_k(model, query, doc_embs, docs, k=sources)\n",
    "\n",
    "    if print_flag:\n",
    "        for score, doc in results:\n",
    "            print(f\"{score:.4f} | {doc}\")\n",
    "\n",
    "\n",
    "    rag_input = {\n",
    "        \"query\": query,\n",
    "        \"research_summaries\": [\n",
    "            {\n",
    "                \"score\": score,\n",
    "                \"id\": text.split('||')[0],\n",
    "                \"text\": text.split('||')[1]\n",
    "            }\n",
    "            for score, text in results[:n]\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI assisntant that uses retrieval augmented generation to answer questions about educational best practices\n",
    "\n",
    "    == Relevant Information ==\n",
    "    Reference Summaries: You will be provided with structured summaries of research papers.\n",
    "    Relevance Filtering: Only use information from the summaries if it is directly relevant to the query.\n",
    "    Answer Generation: Generate concise, accurate, and clear answers to the user query.\n",
    "    Citation: When using information from a summary, include a reference to the summary’s ID.\n",
    "\n",
    "    ==INPUT==\n",
    "    {json.dumps(rag_input, indent=2)}\n",
    "\n",
    "    ==EXAMPLE OUTPUT== \n",
    "    {{\n",
    "    \"answer\": <\"Answer based on relevant summaries.\">,\n",
    "    \"used_summaries\": <[\"id1\", ..., \"idn\"]>\n",
    "    }}\n",
    "\n",
    "    ==IMPORTANT==\n",
    "    - Only respond with the output JSON, nothing before or after; DO NOT inlude \"```json\" or other markdown in your response.\n",
    "    - Maintain a professional and friendly tone.\n",
    "    - Respond only by referencing the given input. If none of the input is relevant to the user query, then respond that you have nothing useful to say.\n",
    "    - Do not elaborate at all in your response outside of the input data.\n",
    "    - Be concise\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd59cbeb",
   "metadata": {},
   "source": [
    "### putting it all together with claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dd6cd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'Research on class size reduction found that decreasing class sizes from 25 to 15 students resulted in a 12% improvement in elementary reading scores, though it had no significant effect on mathematics achievement. However, cost-benefit analysis indicated that targeted tutoring might be a more efficient approach than class size reduction (doc_016).', 'used_summaries': ['doc_016']}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = generate_prompt(query='Tell me about optimal class size?')\n",
    "\n",
    "client = anthropic.Anthropic(api_key=ignore.KEY)\n",
    "\n",
    "response = client.messages.create(\n",
    "    model=\"claude-sonnet-4-5-20250929\",    \n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "response_obj = json.loads(response.content[0].text)\n",
    "\n",
    "print(response_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48c2cb9",
   "metadata": {},
   "source": [
    "# A more production style oop example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "708591ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGPromptGenerator:\n",
    "    def __init__(self, docs: list[str], api_key: str, embedding_model: str = \"all-MiniLM-L6-v2\", claude_model: str = \"claude-sonnet-4-5-20250929\"):\n",
    "        \"\"\"\n",
    "        Initialize the RAG prompt generator and embed the documents.\n",
    "\n",
    "        Args:\n",
    "            docs: List of documents with format \"id||text\".\n",
    "            embedding_model: Name of the SentenceTransformer model to use for embeddings.\n",
    "            claude_model: Which Claude model to use.\n",
    "        \"\"\"\n",
    "        self.docs = docs\n",
    "        self.model = SentenceTransformer(embedding_model)\n",
    "        self.doc_embs = self.model.encode(docs, convert_to_tensor=True, normalize_embeddings=True)\n",
    "        self.claude_model = claude_model\n",
    "        self.client = anthropic.Anthropic(api_key=api_key)\n",
    "\n",
    "    def search_top_k(self, query: str, k: int = 3) -> list[tuple[float, str]]:\n",
    "        \"\"\"Perform a cosine similarity search for a query against precomputed document embeddings.\"\"\"\n",
    "        query_emb = self.model.encode([query], convert_to_tensor=True, normalize_embeddings=True)\n",
    "        sims = util.cos_sim(query_emb, self.doc_embs)[0]\n",
    "        top_k = torch.topk(sims, k=k)\n",
    "        return [(score.item(), self.docs[idx]) for idx, score in zip(top_k.indices, top_k.values)]\n",
    "\n",
    "    def generate_prompt(self, query: str, sources: int = 3, print_flag: bool = False) -> str:\n",
    "        \"\"\"Generate a RAG-style prompt with top-k relevant research summaries.\"\"\"\n",
    "        results = self.search_top_k(query, k=sources)\n",
    "\n",
    "        if print_flag:\n",
    "            for score, doc in results:\n",
    "                print(f\"{score:.4f} | {doc}\")\n",
    "\n",
    "        rag_input = {\n",
    "            \"query\": query,\n",
    "            \"research_summaries\": [\n",
    "                {\n",
    "                    \"score\": score,\n",
    "                    \"id\": text.split('||')[0],\n",
    "                    \"text\": text.split('||')[1]\n",
    "                }\n",
    "                for score, text in results[:sources]\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        You are an AI assistant that uses retrieval-augmented generation to answer questions about educational best practices.\n",
    "\n",
    "        == Relevant Information ==\n",
    "        Reference Summaries: You will be provided with structured summaries of research papers.\n",
    "        Relevance Filtering: Only use information from the summaries if it is directly relevant to the query. You may use mutliple summaries if they are all relevant.\n",
    "        Answer Generation: Generate concise, accurate, and clear answers to the user query.\n",
    "        Citation: When using information from a summary, include a reference to the summary’s ID.\n",
    "\n",
    "        ==INPUT==\n",
    "        {json.dumps(rag_input, indent=2)}\n",
    "\n",
    "        ==EXAMPLE OUTPUT==\n",
    "        {{\n",
    "        \"answer\": <\"Answer based on relevant summaries.\">,\n",
    "        \"used_summaries\": <[\"id1\", ..., \"idn\"]>,\n",
    "        \"all_summaries\": <[\"id1\", ..., \"idn\"]>\n",
    "        }}\n",
    "\n",
    "        ==IMPORTANT==\n",
    "        - Only respond with the output JSON, nothing before or after; DO NOT inlude \"```json\" or other markdown in your response.\n",
    "        - Maintain a professional and friendly tone.\n",
    "        - Respond only by referencing the given input. If none of the input is relevant to the user query, then respond that you have nothing useful to say.\n",
    "        - Do not elaborate at all in your response outside of the input data.\n",
    "        - Be concise\n",
    "\n",
    "        *REMEBER* \n",
    "        - Your response **must be valid JSON only**.\n",
    "        - DO NOT include ```json, ``` or any other markdown syntax.\n",
    "        - Do NOT include explanations, greetings, or extra text—only the JSON.\n",
    "        \"\"\"\n",
    "        return prompt\n",
    "\n",
    "    def query_llm(self, query: str, sources: int = 3, print_flag: bool = False) -> dict:\n",
    "        \"\"\"\n",
    "        Full pipeline: query -> retrieve top summaries -> generate prompt -> call Claude -> return JSON.\n",
    "        \"\"\"\n",
    "        prompt = self.generate_prompt(query, sources=sources, print_flag=print_flag)\n",
    "\n",
    "        response = self.client.messages.create(\n",
    "            model=self.claude_model,\n",
    "            max_tokens=1024,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            response = response.content[0].text.strip(r'```json').strip(r'```')\n",
    "            response_obj = json.loads(response)\n",
    "        except json.JSONDecodeError:\n",
    "            response_obj = {\"error\": \"Failed to parse response JSON\", \"raw_text\": response}\n",
    "\n",
    "        return response_obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6276bda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"answer\": \"Research on outdoor classes shows significant benefits for students. Students who participated in nature-based learning for at least 2 hours per week demonstrated a 26% reduction in stress markers and an 18% improvement in creative problem-solving tasks compared to students in indoor-only settings (doc_012).\",\n",
      "  \"used_summaries\": [\n",
      "    \"doc_012\"\n",
      "  ],\n",
      "  \"all_summaries\": [\n",
      "    \"doc_012\",\n",
      "    \"doc_005\",\n",
      "    \"doc_014\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "rag_generator = RAGPromptGenerator(docs, \n",
    "                                   api_key=ignore.KEY,\n",
    "                                   embedding_model='all-MiniLM-L6-v2', \n",
    "                                   claude_model='claude-sonnet-4-5-20250929')\n",
    "\n",
    "query = \"What do we know about classes that are outdoors?\"\n",
    "response = rag_generator.query_llm(query, sources=3)\n",
    "\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6013a799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"answer\": \"Based on research with 1,500 ESL students, allowing code-switching between students' native language and English during initial concept introduction can improve comprehension by 44%. This approach challenges English-only immersion policies and suggests that strategic use of students' native languages can be an effective instructional strategy for English language learners (doc_013).\",\n",
      "  \"used_summaries\": [\n",
      "    \"doc_013\"\n",
      "  ],\n",
      "  \"all_summaries\": [\n",
      "    \"doc_013\",\n",
      "    \"doc_010\",\n",
      "    \"doc_016\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query = \"How can I help my students who speak english as a second language?\"\n",
    "response = rag_generator.query_llm(query, sources=3)\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7287d07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"answer\": \"While there is no direct research in the provided summaries about meditation specifically done outside, relevant findings suggest potential benefits. Mindfulness meditation programs for high school students showed a 15% reduction in test anxiety and 8% improvement in test scores, though these effects required a full 8-week program (doc_020). Separately, outdoor education programs demonstrated that students spending at least 2 hours per week in nature-based learning experienced a 26% reduction in stress markers and 18% improvement in creative problem-solving compared to indoor-only groups (doc_012). Combining meditation with outdoor settings could potentially leverage benefits from both approaches, though no specific research on this combination is available in the current data.\",\n",
      "  \"used_summaries\": [\n",
      "    \"doc_020\",\n",
      "    \"doc_012\"\n",
      "  ],\n",
      "  \"all_summaries\": [\n",
      "    \"doc_020\",\n",
      "    \"doc_012\",\n",
      "    \"doc_019\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query = \"Would meditating outside be useful to my students?\"\n",
    "response = rag_generator.query_llm(query, sources=3)\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e64c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
