{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5272e94c",
   "metadata": {},
   "source": [
    "# RAG Research Summarizer with Claude (Proof of Concept)\n",
    "This script uses Anthropic's Claude to answer queries using relevant research summaries.\n",
    "\n",
    "## Setup:\n",
    "1. Add your API key to a file called ignore.py at the same directory level as this script:\n",
    "\n",
    "    KEY = \"your_claude_api_key_here\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf881731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (2.8.0)\n",
      "Requirement already satisfied: sentence-transformers in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (5.1.2)\n",
      "Requirement already satisfied: anthropic in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (0.72.0)\n",
      "Requirement already satisfied: jinja2 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: fsspec in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: networkx in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: filelock in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: Pillow in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: tqdm in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (4.57.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: scipy in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from anthropic) (2.12.4)\n",
      "Requirement already satisfied: sniffio in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from anthropic) (1.3.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from anthropic) (1.9.0)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.15 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from anthropic) (0.17.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from anthropic) (0.11.1)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from anthropic) (0.28.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from anthropic) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->anthropic) (3.11)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->anthropic) (1.3.0)\n",
      "Requirement already satisfied: certifi in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.25.0->anthropic) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: requests in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->anthropic) (2.41.5)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/jrosenb8/Library/Python/3.9/lib/python/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch sentence-transformers anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e298a7c2",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8000a0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jrosenb8/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jrosenb8/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import ignore\n",
    "\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import anthropic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22617b3b",
   "metadata": {},
   "source": [
    "# extract documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5551ddec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_001||A longitudinal study of 1,200 middle school students found that incorporating spaced repetition into mathematics curriculum improved long-term retention by 42% compared to massed practice. Students who reviewed concepts at intervals of 1, 3, and 7 days showed significantly better performance on assessments administered three months later.\n",
      "doc_002||Research examining 500 undergraduate students revealed that handwritten notes led to 23% better conceptual understanding compared to laptop note-taking. The constraint of slower handwriting appeared to force students to process and synthesize information more deeply during lectures.\n",
      "doc_003||A meta-analysis of 74 studies found that peer tutoring programs increased academic achievement by an average effect size of 0.59 standard deviations. Benefits were particularly pronounced when tutors were trained in questioning techniques and given structured materials.\n",
      "doc_004||Investigation of 15 elementary schools implementing project-based learning showed mixed results: while student engagement increased by 67%, standardized test scores showed no significant improvement in the first two years of implementation. Teachers reported needing 18-24 months to effectively adapt their practice.\n",
      "doc_005||Analysis of online learning outcomes during 2020-2021 revealed that synchronous video classes with breakout rooms achieved 89% of the learning gains of in-person instruction, while asynchronous-only formats achieved only 64%. Student isolation was the primary predictor of poor outcomes.\n"
     ]
    }
   ],
   "source": [
    "docs = json.load(open('./documents.json', 'r'))\n",
    "docs = [f'{k}||{v}' for k, v in docs.items()]  # Make them a list with some metadata fusion.\n",
    "\n",
    "for doc in docs[:5]:  # print a few docs as an example\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34302a0e",
   "metadata": {},
   "source": [
    "# cosine similarity function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92af8a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_top_k(model: SentenceTransformer, query: str, doc_embs: torch.Tensor, docs: list[str], k: int = 3) -> list[tuple[float, str]]:\n",
    "    \"\"\"\n",
    "    Perform a cosine similarity search for a query against precomputed document embeddings.\n",
    "\n",
    "    Args:\n",
    "        model (SentenceTransformer): Preloaded Huggingface embedding model.\n",
    "        query (str): Query string.\n",
    "        doc_embs (torch.Tensor): Precomputed document embeddings (normalized).\n",
    "        docs (List[str]): Original documents corresponding to embeddings.\n",
    "        k (int, optional): Number of top results to return. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        list[Tuple[float, str]]: List of (similarity_score, document) tuples.\n",
    "    \"\"\"\n",
    "    query_emb = model.encode([query], convert_to_tensor=True, normalize_embeddings=True)\n",
    "    sims = util.cos_sim(query_emb, doc_embs)[0]  # shape: [num_docs]\n",
    "    top_k = torch.topk(sims, k=k)\n",
    "    return [(score.item(), docs[idx]) for idx, score in zip(top_k.indices, top_k.values)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b34cce6",
   "metadata": {},
   "source": [
    "# build model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2855932",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "doc_embs = model.encode(docs, convert_to_tensor=True, normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d26b30a",
   "metadata": {},
   "source": [
    "### example search usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9dd3a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5860 | doc_012||Research on outdoor education programs found that students who spent at least 2 hours per week in nature-based learning showed 26% reduction in stress markers and 18% improvement in creative problem-solving tasks compared to indoor-only control groups.\n",
      "0.3282 | doc_004||Investigation of 15 elementary schools implementing project-based learning showed mixed results: while student engagement increased by 67%, standardized test scores showed no significant improvement in the first two years of implementation. Teachers reported needing 18-24 months to effectively adapt their practice.\n",
      "0.2837 | doc_005||Analysis of online learning outcomes during 2020-2021 revealed that synchronous video classes with breakout rooms achieved 89% of the learning gains of in-person instruction, while asynchronous-only formats achieved only 64%. Student isolation was the primary predictor of poor outcomes.\n"
     ]
    }
   ],
   "source": [
    "query = 'what do we know about outdoor education'\n",
    "n = 3\n",
    "\n",
    "results = search_top_k(model, query, doc_embs, docs, k=n)\n",
    "\n",
    "for score, doc in results:\n",
    "    print(f\"{score:.4f} | {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a167ffd",
   "metadata": {},
   "source": [
    "# prompt building and generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27dd541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(query: str, sources: int = 3, print_flag: bool = False) -> str:\n",
    "    results = search_top_k(model, query, doc_embs, docs, k=sources)\n",
    "\n",
    "    if print_flag:\n",
    "        for score, doc in results:\n",
    "            print(f\"{score:.4f} | {doc}\")\n",
    "\n",
    "\n",
    "    rag_input = {\n",
    "        \"query\": query,\n",
    "        \"research_summaries\": [\n",
    "            {\n",
    "                \"score\": score,\n",
    "                \"id\": text.split('||')[0],\n",
    "                \"text\": text.split('||')[1]\n",
    "            }\n",
    "            for score, text in results[:n]\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI assisntant that uses retrieval augmented generation to answer questions about educational best practices\n",
    "\n",
    "    == Relevant Information ==\n",
    "    Reference Summaries: You will be provided with structured summaries of research papers.\n",
    "    Relevance Filtering: Only use information from the summaries if it is directly relevant to the query.\n",
    "    Answer Generation: Generate concise, accurate, and clear answers to the user query.\n",
    "    Citation: When using information from a summary, include a reference to the summary’s ID.\n",
    "\n",
    "    ==INPUT==\n",
    "    {json.dumps(rag_input, indent=2)}\n",
    "\n",
    "    ==EXAMPLE OUTPUT== \n",
    "    {{\n",
    "    \"answer\": <\"Answer based on relevant summaries.\">,\n",
    "    \"used_summaries\": <[\"id1\", ..., \"idn\"]>\n",
    "    }}\n",
    "\n",
    "    ==IMPORTANT==\n",
    "    - Only respond with the output JSON, nothing before or after; DO NOT inlude \"```json\" or other markdown in your response.\n",
    "    - Maintain a professional and friendly tone.\n",
    "    - Respond only by referencing the given input. If none of the input is relevant to the user query, then respond that you have nothing useful to say.\n",
    "    - Do not elaborate at all in your response outside of the input data.\n",
    "    - Be concise\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd59cbeb",
   "metadata": {},
   "source": [
    "### putting it all together with claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd6cd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': \"Based on the available research, there is evidence that reducing class size from 25 to 15 students can have positive effects on student achievement, particularly in elementary reading where a 12% improvement was observed. However, the same study found no significant effect on mathematics achievement. It's worth noting that the research also indicated that cost-benefit analysis suggested targeted tutoring might be more efficient than class size reduction, suggesting that smaller classes alone may not be the most cost-effective intervention.\", 'used_summaries': ['doc_016']}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = generate_prompt(query='Tell me about optimal class size?')\n",
    "\n",
    "client = anthropic.Anthropic(api_key=ignore.KEY)\n",
    "\n",
    "response = client.messages.create(\n",
    "    model=\"claude-sonnet-4-5-20250929\",    \n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "response_obj = json.loads(response.content[0].text)\n",
    "\n",
    "print(response_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48c2cb9",
   "metadata": {},
   "source": [
    "# A more production style oop example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708591ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGPromptGenerator:\n",
    "    def __init__(self, docs: list[str], api_key: str, embedding_model: str = \"all-MiniLM-L6-v2\", claude_model: str = \"claude-sonnet-4-5-20250929\"):\n",
    "        \"\"\"\n",
    "        Initialize the RAG prompt generator and embed the documents.\n",
    "\n",
    "        Args:\n",
    "            docs: List of documents with format \"id||text\".\n",
    "            embedding_model: Name of the SentenceTransformer model to use for embeddings.\n",
    "            claude_model: Which Claude model to use.\n",
    "        \"\"\"\n",
    "        self.docs = docs\n",
    "        self.model = SentenceTransformer(embedding_model)\n",
    "        self.doc_embs = self.model.encode(docs, convert_to_tensor=True, normalize_embeddings=True)\n",
    "        self.claude_model = claude_model\n",
    "        self.client = anthropic.Anthropic(api_key=api_key)\n",
    "\n",
    "    def search_top_k(self, query: str, k: int = 3) -> list[tuple[float, str]]:\n",
    "        \"\"\"Perform a cosine similarity search for a query against precomputed document embeddings.\"\"\"\n",
    "        query_emb = self.model.encode([query], convert_to_tensor=True, normalize_embeddings=True)\n",
    "        sims = util.cos_sim(query_emb, self.doc_embs)[0]\n",
    "        top_k = torch.topk(sims, k=k)\n",
    "        return [(score.item(), self.docs[idx]) for idx, score in zip(top_k.indices, top_k.values)]\n",
    "\n",
    "    def generate_prompt(self, query: str, sources: int = 3, print_flag: bool = False) -> str:\n",
    "        \"\"\"Generate a RAG-style prompt with top-k relevant research summaries.\"\"\"\n",
    "        results = self.search_top_k(query, k=sources)\n",
    "\n",
    "        if print_flag:\n",
    "            for score, doc in results:\n",
    "                print(f\"{score:.4f} | {doc}\")\n",
    "\n",
    "        rag_input = {\n",
    "            \"query\": query,\n",
    "            \"research_summaries\": [\n",
    "                {\n",
    "                    \"score\": score,\n",
    "                    \"id\": text.split('||')[0],\n",
    "                    \"text\": text.split('||')[1]\n",
    "                }\n",
    "                for score, text in results[:sources]\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        You are an AI assistant that uses retrieval-augmented generation to answer questions about educational best practices.\n",
    "\n",
    "        == Relevant Information ==\n",
    "        Reference Summaries: You will be provided with structured summaries of research papers.\n",
    "        Relevance Filtering: Only use information from the summaries if it is directly relevant to the query.\n",
    "        Answer Generation: Generate concise, accurate, and clear answers to the user query.\n",
    "        Citation: When using information from a summary, include a reference to the summary’s ID.\n",
    "\n",
    "        ==INPUT==\n",
    "        {json.dumps(rag_input, indent=2)}\n",
    "\n",
    "        ==EXAMPLE OUTPUT==\n",
    "        {{\n",
    "        \"answer\": <\"Answer based on relevant summaries.\">,\n",
    "        \"used_summaries\": <[\"id1\", ..., \"idn\"]>\n",
    "        }}\n",
    "\n",
    "        ==IMPORTANT==\n",
    "        - Only respond with the output JSON, nothing before or after; DO NOT inlude \"```json\" or other markdown in your response.\n",
    "        - Maintain a professional and friendly tone.\n",
    "        - Respond only by referencing the given input. If none of the input is relevant to the user query, then respond that you have nothing useful to say.\n",
    "        - Do not elaborate at all in your response outside of the input data.\n",
    "        - Be concise\n",
    "        \"\"\"\n",
    "        return prompt\n",
    "\n",
    "    def query_llm(self, query: str, sources: int = 3, print_flag: bool = False) -> dict:\n",
    "        \"\"\"\n",
    "        Full pipeline: query -> retrieve top summaries -> generate prompt -> call Claude -> return JSON.\n",
    "        \"\"\"\n",
    "        prompt = self.generate_prompt(query, sources=sources, print_flag=print_flag)\n",
    "\n",
    "        response = self.client.messages.create(\n",
    "            model=self.claude_model,\n",
    "            max_tokens=1024,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            response_obj = json.loads(response.content[0].text)\n",
    "        except json.JSONDecodeError:\n",
    "            response_obj = {\"error\": \"Failed to parse response JSON\", \"raw_text\": response.content[0].text}\n",
    "\n",
    "        return response_obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6276bda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"answer\": \"Research shows that outdoor classes can have significant benefits for students. Students who participated in nature-based learning for at least 2 hours per week demonstrated a 26% reduction in stress markers and an 18% improvement in creative problem-solving tasks compared to students in indoor-only settings (doc_012).\",\n",
      "  \"used_summaries\": [\n",
      "    \"doc_012\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "rag_generator = RAGPromptGenerator(docs, \n",
    "                                   api_key=ignore.KEY,\n",
    "                                   embedding_model='all-MiniLM-L6-v2', \n",
    "                                   claude_model='claude-sonnet-4-5-20250929')\n",
    "\n",
    "query = \"What do we know about classes that are outdoors?\"\n",
    "response = rag_generator.query_llm(query, sources=3)\n",
    "\n",
    "print(json.dumps(response, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
