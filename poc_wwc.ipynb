{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5272e94c",
   "metadata": {},
   "source": [
    "# RAG Research Summarizer with Claude (Proof of Concept)\n",
    "This script uses Anthropic's Claude to answer queries using relevant research summaries.\n",
    "\n",
    "## Setup:\n",
    "1. Add your API key to a file called ignore.py at the same directory level as this script:\n",
    "\n",
    "    KEY = \"your_claude_api_key_here\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf881731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qq torch sentence-transformers anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e298a7c2",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8000a0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import ignore\n",
    "\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import anthropic\n",
    "\n",
    "\n",
    "DOCUMENT_STORE_PATH: str = './all_wwc.json'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22617b3b",
   "metadata": {},
   "source": [
    "# extract documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5551ddec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dddm_pg_092909.pdf__1__0||Using Student Achievement Data to  \n",
      "Support Instructional Decision Making\n",
      "Using Student Achievement Data to  \n",
      "Support Instructional Decision Making\n",
      "NCEE 2009-4067\n",
      "U.S. DEPARTMENT OF EDUCATION\n",
      "IES PRACTICE GUIDE\n",
      "WHAT WORKS CLEARINGHOUSE\n",
      "\n",
      "dddm_pg_092909.pdf__2__0||The Institute of Education Sciences (IES) publishes practice guides in education \n",
      "to bring the best available evidence and expertise to bear on the types of challenges \n",
      "that cannot currently be addressed by a single intervention or program. Authors of \n",
      "practice guides seldom conduct the types of systematic literature searches that are \n",
      "the backbone of a meta-analysis, although they take advantage of such work when \n",
      "it is already published. Instead, authors use their expertise to identify the most im­\n",
      "portant research with respect to their recommendations and conduct a search of \n",
      "recent publications to ensure that the research supporting the recommendations \n",
      "is up-to-date. \n",
      "Unique to IES-sponsored practice guides is that they are subjected to rigorous exter­\n",
      "nal peer review through the same office that is responsible for independent reviews \n",
      "of other IES publications. A critical task for peer reviewers of a practice guide is to\n",
      "\n",
      "dddm_pg_092909.pdf__2__1||nal peer review through the same office that is responsible for independent reviews \n",
      "of other IES publications. A critical task for peer reviewers of a practice guide is to \n",
      "determine whether the evidence cited in support of particular recommendations is \n",
      "up-to-date and that studies of similar or better quality that point in a different di­\n",
      "rection have not been ignored. Because practice guides depend on the expertise of \n",
      "their authors and their group decision making, the content of a practice guide is not \n",
      "and should not be viewed as a set of recommendations that in every case depends \n",
      "on and flows inevitably from scientific research.\n",
      "The goal of this practice guide is to formulate specific and coherent evidence-based \n",
      "recommendations for use by educators and education administrators to create the \n",
      "organizational conditions necessary to make decisions using student achievement \n",
      "data in classrooms, schools, and districts. The guide provides practical, clear in­\n",
      "\n",
      "dddm_pg_092909.pdf__2__2||organizational conditions necessary to make decisions using student achievement \n",
      "data in classrooms, schools, and districts. The guide provides practical, clear in­\n",
      "formation on critical topics related to data-based decision making and is based on \n",
      "the best available evidence as judged by the panel. Recommendations presented in \n",
      "this guide should not be construed to imply that no further research is warranted \n",
      "on the effectiveness of particular strategies for data-based decision making.\n",
      "\n",
      "dddm_pg_092909.pdf__3__0||Using Student Achievement \n",
      "Data to Support Instructional \n",
      "Decision Making\n",
      "September 2009\n",
      "Panel\n",
      "Laura Hamilton (Chair)\n",
      "RAND Corporationrrporationraorationn\n",
      "Richard Halverson\n",
      "University of Wisconsin–Madisonnniversity of Wisconsin–Madisonrersity of Wisconsin–Madisoncisconsin–Madisonnsconsin–Madisonnonsin–Madisonadsin–Madisonn\n",
      "Sharnell S. Jackson\n",
      "Chicago Public Schools cacago Public Schools Pu\n",
      "c Sc\n",
      "Ellen Mandinach\n",
      "CNA EducationEEducationducaEducationn\n",
      "Jonathan A. Supovitz\n",
      "University of Pennsylvanianniversity of Pennsylvaniarersity of PennsylvaniaPf Pennsylvaniann Pennsylvaniaannsylvaniaa\n",
      "Jeffrey C. Wayman\n",
      "The University of Texas at Austin\n",
      "Staff\n",
      "Cassandra Pickens\n",
      "Emily Sama Martin\n",
      "Mathematica Policy Researchaathematica Policy Researchmaematica Policy Researchcaatica Policy ResearchPtica Policy Researchca Policy Researcharccy Research\n",
      "Jennifer L. Steele\n",
      "RAND Corporationrrporationraorationn\n",
      "NCEE 2009-4067\n",
      "U.S. DEPARTMENT OF EDUCATION\n",
      "IES PRACTICE GUIDE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs = json.load(open(DOCUMENT_STORE_PATH, 'r'))\n",
    "docs = [f'{k}||{v}' for k, v in docs.items()]  # Make them a list with some metadata fusion.\n",
    "\n",
    "for doc in docs[:5]:  # print a few docs as an example\n",
    "    print(doc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34302a0e",
   "metadata": {},
   "source": [
    "# cosine similarity function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92af8a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_top_k(model: SentenceTransformer, query: str, doc_embs: torch.Tensor, docs: list[str], k: int = 3) -> list[tuple[float, str]]:\n",
    "    \"\"\"\n",
    "    Perform a cosine similarity search for a query against precomputed document embeddings.\n",
    "\n",
    "    Args:\n",
    "        model (SentenceTransformer): Preloaded Huggingface embedding model.\n",
    "        query (str): Query string.\n",
    "        doc_embs (torch.Tensor): Precomputed document embeddings (normalized).\n",
    "        docs (List[str]): Original documents corresponding to embeddings.\n",
    "        k (int, optional): Number of top results to return. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        list[Tuple[float, str]]: List of (similarity_score, document) tuples.\n",
    "    \"\"\"\n",
    "    query_emb = model.encode([query], convert_to_tensor=True, normalize_embeddings=True)\n",
    "    sims = util.cos_sim(query_emb, doc_embs)[0]  # shape: [num_docs]\n",
    "    top_k = torch.topk(sims, k=k)\n",
    "    return [(score.item(), docs[idx]) for idx, score in zip(top_k.indices, top_k.values)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b34cce6",
   "metadata": {},
   "source": [
    "# build model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2855932",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "doc_embs = model.encode(docs, convert_to_tensor=True, normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d26b30a",
   "metadata": {},
   "source": [
    "### example search usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9dd3a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5050 | adlit_pg_082608.pdf__55__4||of the first study42 indicated that students \n",
      "39.  This was the content taught in Guthrie et al. \n",
      "(1999). In Guthrie et al. (2000), teachers taught \n",
      "environmental adaptation (life science theme) \n",
      "in the fall and weather (earth science theme) in \n",
      "the spring.\n",
      "40.  Guthrie et al. (1999).\n",
      "41.  Guthrie et al. (2000).\n",
      "42.  Guthrie et al. (1999).\n",
      "\n",
      "0.4637 | ost_pg_072109.pdf__47__2||expert on a number of national research \n",
      "and development projects and was recently \n",
      "named to the 15-member Urban Education \n",
      "Research Task Force established to advise \n",
      "the U.S. Department of Education on issues \n",
      "affecting urban education. Among his vari­\n",
      "ous awards and honors, most recently Dr. \n",
      "Borman received the 2008 American Educa­\n",
      "tional Research Association (AERA) Palmer \n",
      "O. Johnson Award and was recognized for \n",
      "his contributions to education research by \n",
      "selection as an AERA Fellow.\n",
      "Jeffrey Capizzano is vice president of pub­\n",
      "lic policy and research at Teaching Strate­\n",
      "gies, Inc. Mr. Capizzano brings to the panel \n",
      "extensive research and evaluation experi­\n",
      "ence in the areas of OST, youth develop­\n",
      "ment, and summer learning programs and \n",
      "is skilled in a variety of quantitative and \n",
      "qualitative data collection and analysis \n",
      "techniques. Mr. Capizzano was involved \n",
      "in an experimental evaluation of an accel­\n",
      "erated learning summer program, Build­\n",
      "\n",
      "0.4622 | dp_pg_090308.pdf__5__1||26\n",
      "Recommendation 5. Personalize the learning environment and instructional process \n",
      "(schoolwide intervention)\n",
      "30\n",
      "Recommendation 6. Provide rigorous and relevant instruction to better engage \n",
      "students in learning and provide the skills needed to graduate and to serve them \n",
      "after they leave school (schoolwide intervention)\n",
      "34\n",
      "Conclusio\n",
      "39\n",
      "Appendix A. Postscript from the Institute of Education Science\n",
      "40\n",
      "Appendix B. About the author\n",
      "43\n",
      "Appendix C. Disclosure of potential conflicts of interes\n",
      "45\n",
      "Appendix D. Technical information on the studie\n",
      "46\n",
      "Reference\n",
      "59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = 'what do we know about outdoor education'\n",
    "n = 3\n",
    "\n",
    "results = search_top_k(model, query, doc_embs, docs, k=n)\n",
    "\n",
    "for score, doc in results:\n",
    "    print(f\"{score:.4f} | {doc}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a167ffd",
   "metadata": {},
   "source": [
    "# prompt building and generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b27dd541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(query: str, sources: int = 3, print_flag: bool = False) -> str:\n",
    "    results = search_top_k(model, query, doc_embs, docs, k=sources)\n",
    "\n",
    "    if print_flag:\n",
    "        for score, doc in results:\n",
    "            print(f\"{score:.4f} | {doc}\")\n",
    "\n",
    "\n",
    "    rag_input = {\n",
    "        \"query\": query,\n",
    "        \"research_summaries\": [\n",
    "            {\n",
    "                \"score\": score,\n",
    "                \"id\": text.split('||')[0],\n",
    "                \"text\": text.split('||')[1]\n",
    "            }\n",
    "            for score, text in results[:n]\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI assisntant that uses retrieval augmented generation to answer questions about educational best practices\n",
    "\n",
    "    == Relevant Information ==\n",
    "    Reference Summaries: You will be provided with structured summaries of research papers.\n",
    "    Relevance Filtering: Only use information from the summaries if it is directly relevant to the query.\n",
    "    Answer Generation: Generate concise, accurate, and clear answers to the user query.\n",
    "    Citation: When using information from a summary, include a reference to the summary’s ID.\n",
    "\n",
    "    ==INPUT==\n",
    "    {json.dumps(rag_input, indent=2)}\n",
    "\n",
    "    ==EXAMPLE OUTPUT== \n",
    "    {{\n",
    "    \"answer\": <\"Answer based on relevant summaries.\">,\n",
    "    \"used_summaries\": <[\"id1\", ..., \"idn\"]>\n",
    "    }}\n",
    "\n",
    "    ==IMPORTANT==\n",
    "    - Only respond with the output JSON, nothing before or after; DO NOT inlude \"```json\" or other markdown in your response.\n",
    "    - Maintain a professional and friendly tone.\n",
    "    - Respond only by referencing the given input. If none of the input is relevant to the user query, then respond that you have nothing useful to say.\n",
    "    - Do not elaborate at all in your response outside of the input data.\n",
    "    - Be concise\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd59cbeb",
   "metadata": {},
   "source": [
    "### putting it all together with claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd6cd86",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 12\u001b[0m\n\u001b[1;32m      3\u001b[0m client \u001b[38;5;241m=\u001b[39m anthropic\u001b[38;5;241m.\u001b[39mAnthropic(api_key\u001b[38;5;241m=\u001b[39mignore\u001b[38;5;241m.\u001b[39mKEY)\n\u001b[1;32m      5\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      6\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclaude-sonnet-4-5-20250929\u001b[39m\u001b[38;5;124m\"\u001b[39m,    \n\u001b[1;32m      7\u001b[0m     max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     ]\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m response_obj \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(response_obj)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = generate_prompt(query='Tell me about optimal class size?')\n",
    "\n",
    "client = anthropic.Anthropic(api_key=ignore.KEY)\n",
    "\n",
    "response = client.messages.create(\n",
    "    model=\"claude-sonnet-4-5-20250929\",    \n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "response_obj = json.loads(response.content[0].text)\n",
    "\n",
    "print(response_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48c2cb9",
   "metadata": {},
   "source": [
    "# A more production style oop example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "708591ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGPromptGenerator:\n",
    "    def __init__(self, docs: list[str], api_key: str, embedding_model: str = \"all-MiniLM-L6-v2\", claude_model: str = \"claude-sonnet-4-5-20250929\"):\n",
    "        \"\"\"\n",
    "        Initialize the RAG prompt generator and embed the documents.\n",
    "\n",
    "        Args:\n",
    "            docs: List of documents with format \"id||text\".\n",
    "            embedding_model: Name of the SentenceTransformer model to use for embeddings.\n",
    "            claude_model: Which Claude model to use.\n",
    "        \"\"\"\n",
    "        self.docs = docs\n",
    "        self.model = SentenceTransformer(embedding_model)\n",
    "        self.doc_embs = self.model.encode(docs, convert_to_tensor=True, normalize_embeddings=True)\n",
    "        self.claude_model = claude_model\n",
    "        self.client = anthropic.Anthropic(api_key=api_key)\n",
    "\n",
    "    def search_top_k(self, query: str, k: int = 3) -> list[tuple[float, str]]:\n",
    "        \"\"\"Perform a cosine similarity search for a query against precomputed document embeddings.\"\"\"\n",
    "        query_emb = self.model.encode([query], convert_to_tensor=True, normalize_embeddings=True)\n",
    "        sims = util.cos_sim(query_emb, self.doc_embs)[0]\n",
    "        top_k = torch.topk(sims, k=k)\n",
    "        return [(score.item(), self.docs[idx]) for idx, score in zip(top_k.indices, top_k.values)]\n",
    "\n",
    "    def generate_prompt(self, query: str, sources: int = 3, print_flag: bool = False) -> str:\n",
    "        \"\"\"Generate a RAG-style prompt with top-k relevant research summaries.\"\"\"\n",
    "        results = self.search_top_k(query, k=sources)\n",
    "\n",
    "        if print_flag:\n",
    "            for score, doc in results:\n",
    "                print(f\"{score:.4f} | {doc}\")\n",
    "\n",
    "        rag_input = {\n",
    "            \"query\": query,\n",
    "            \"research_summaries\": [\n",
    "                {\n",
    "                    \"score\": score,\n",
    "                    \"id\": text.split('||')[0],\n",
    "                    \"text\": text.split('||')[1]\n",
    "                }\n",
    "                for score, text in results[:sources]\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        You are an AI assistant that uses retrieval-augmented generation to answer questions about educational best practices.\n",
    "\n",
    "        == Relevant Information ==\n",
    "        Reference Summaries: You will be provided with structured summaries of research papers.\n",
    "        Relevance Filtering: Only use information from the summaries if it is directly relevant to the query. You may use mutliple summaries if they are all relevant.\n",
    "        Answer Generation: Generate concise, accurate, and clear answers to the user query.\n",
    "        Citation: When using information from a summary, include a reference to the summary IDs - inline when they are used.\n",
    "\n",
    "        ==INPUT==\n",
    "        {json.dumps(rag_input, indent=2)}\n",
    "\n",
    "        ==EXAMPLE OUTPUT==\n",
    "        {{\n",
    "        \"answer\": <\"Answer based on relevant summaries.\">,\n",
    "        \"used_summaries\": <[\"id1\", ..., \"idn\"]>,\n",
    "        \"all_summaries\": <[\"id1\", ..., \"idn\"]>\n",
    "        }}\n",
    "\n",
    "        ==IMPORTANT==\n",
    "        - Only respond with the output JSON, nothing before or after; DO NOT inlude \"```json\" or other markdown in your response.\n",
    "        - Maintain a professional and friendly tone.\n",
    "        - Respond only by referencing the given input. If none of the input is relevant to the user query, then respond that you have nothing useful to say.\n",
    "        - Do not elaborate at all in your response outside of the input data.\n",
    "        - Be concise\n",
    "\n",
    "        *REMEBER* \n",
    "        - Your response **must be valid JSON only**.\n",
    "        - DO NOT include ```json, ``` or any other markdown syntax.\n",
    "        - Do NOT include explanations, greetings, or extra text—only the JSON.\n",
    "        \"\"\"\n",
    "        return prompt\n",
    "\n",
    "    def query_llm(self, query: str, sources: int = 3, print_flag: bool = False) -> dict:\n",
    "        \"\"\"\n",
    "        Full pipeline: query -> retrieve top summaries -> generate prompt -> call Claude -> return JSON.\n",
    "        \"\"\"\n",
    "        prompt = self.generate_prompt(query, sources=sources, print_flag=print_flag)\n",
    "\n",
    "        response = self.client.messages.create(\n",
    "            model=self.claude_model,\n",
    "            max_tokens=1024,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            response = response.content[0].text.strip(r'```json').strip(r'```')\n",
    "            response_obj = json.loads(response)\n",
    "        except json.JSONDecodeError:\n",
    "            response_obj = {\"error\": \"Failed to parse response JSON\", \"raw_text\": response}\n",
    "\n",
    "        return response_obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6276bda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"answer\": \"The provided research summaries do not contain specific information about classes that are conducted outdoors in nature. The summaries discuss various educational approaches including hands-on activities, observation and personalization phases in instruction, and connecting students to topics like ecosystems and weather, but none explicitly address outdoor or nature-based classroom settings.\",\n",
      "  \"used_summaries\": [],\n",
      "  \"all_summaries\": [\n",
      "    \"adlit_pg_082608.pdf__55__4\",\n",
      "    \"adlit_pg_082608.pdf__55__2\",\n",
      "    \"20072003.pdf__15__2\",\n",
      "    \"WWC-practice-guide-reading-intervention-full-text.pdf__30__1\",\n",
      "    \"TO4_PRACTICE_GUIDE_Preparing-for-School_07222022_v6.pdf__66__1\",\n",
      "    \"WWC-practice-guide-reading-intervention-full-text.pdf__30__2\",\n",
      "    \"english_learners_pg_040114.pdf__52__1\",\n",
      "    \"readingcomp_pg_092810.pdf__41__4\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "rag_generator = RAGPromptGenerator(docs, \n",
    "                                   api_key=ignore.KEY,\n",
    "                                   embedding_model='all-MiniLM-L6-v2', \n",
    "                                   claude_model='claude-sonnet-4-5-20250929')\n",
    "\n",
    "query = \"What do we know about classes that are outdoors in nature?\"\n",
    "response = rag_generator.query_llm(query, sources=8)\n",
    "\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6013a799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"answer\": \"To help students who speak English as a second language, research recommends several strategies: 1) Teach academic vocabulary intensively across several days using varied instructional activities (english_learners_pg_040114.pdf__10__2). 2) Integrate oral and written English language instruction into content-area teaching across subjects like math, science, and history (english_learners_pg_040114.pdf__10__2, english_learners_pg_040114.pdf__47__1). 3) Provide regular structured opportunities to develop written language skills (english_learners_pg_040114.pdf__10__2). 4) Group students heterogeneously by language proficiency so stronger English speakers can model language for less proficient students (english_learners_pg_040114.pdf__47__1). 5) Allow brief but frequent peer discussions throughout the day where students explain content using academic vocabulary, and permit emergent learners to discuss in their primary language to promote comprehension (english_learners_pg_040114.pdf__47__1). 6) Provide small-group instructional interventions for students struggling with literacy and English language development, addressing areas like phonemic awareness, decoding, and reading comprehension (english_learners_pg_040114.pdf__66__0). Note that these language-focused strategies also benefit native English speakers from low-income backgrounds who demonstrate similar language weaknesses (english_learners_pg_040114.pdf__53__0).\",\n",
      "  \"used_summaries\": [\n",
      "    \"english_learners_pg_040114.pdf__10__2\",\n",
      "    \"english_learners_pg_040114.pdf__47__1\",\n",
      "    \"english_learners_pg_040114.pdf__53__0\",\n",
      "    \"english_learners_pg_040114.pdf__66__0\"\n",
      "  ],\n",
      "  \"all_summaries\": [\n",
      "    \"english_learners_pg_040114.pdf__53__0\",\n",
      "    \"english_learners_pg_040114.pdf__47__1\",\n",
      "    \"20074011.pdf__29__2\",\n",
      "    \"english_learners_pg_040114.pdf__66__0\",\n",
      "    \"english_learners_pg_040114.pdf__10__2\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query = \"How can I help my students who speak english as a second language?\"\n",
    "response = rag_generator.query_llm(query, sources=5)\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7287d07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"answer\": \"Based on the available research summaries, there is no directly relevant information about meditating outside or outdoor meditation practices for students. The summaries discuss self-monitoring techniques, classroom environment modifications, and teaching social-emotional skills like deep breathing exercises, but none specifically address outdoor meditation or its potential benefits for students.\",\n",
      "  \"used_summaries\": [],\n",
      "  \"all_summaries\": [\n",
      "    \"behavioral-interventions-practice-guide_v3a_508a.pdf__67__1\",\n",
      "    \"behavior_pg_092308.pdf__31__0\",\n",
      "    \"TO4_PRACTICE_GUIDE_Preparing-for-School_07222022_v6.pdf__17__2\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query = \"Would meditating outside be useful to my students?\"\n",
    "response = rag_generator.query_llm(query, sources=3)\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04458c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
